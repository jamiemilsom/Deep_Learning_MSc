{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n",
      "Running on NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "    \n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "print(\"Running on \" + torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests Route - Score: 0.77033"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y = train_data[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", 'Embarked']\n",
    "X = pd.get_dummies(train_data[features])\n",
    "X_test = pd.get_dummies(test_data[features])\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "rfc.fit(X, y)\n",
    "predictions = rfc.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('titanic_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.394665</td>\n",
       "      <td>-0.490508</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.354749</td>\n",
       "      <td>-0.507194</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.506849</td>\n",
       "      <td>-0.453112</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.181385</td>\n",
       "      <td>-0.473739</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.565419</td>\n",
       "      <td>-0.400792</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      Fare  Cabin  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
       "0  0.394665 -0.490508      0     False     False      True       False   \n",
       "1  1.354749 -0.507194      0     False     False      True        True   \n",
       "2  2.506849 -0.453112      0     False      True     False       False   \n",
       "3 -0.181385 -0.473739      0     False     False      True       False   \n",
       "4 -0.565419 -0.400792      0     False     False      True        True   \n",
       "\n",
       "   Sex_male  SibSp_0  SibSp_1  ...  Title_Dr  Title_Master  Title_Miss  \\\n",
       "0      True     True    False  ...     False         False       False   \n",
       "1     False    False     True  ...     False         False       False   \n",
       "2      True     True    False  ...     False         False       False   \n",
       "3      True     True    False  ...     False         False       False   \n",
       "4     False    False     True  ...     False         False       False   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Ms  Title_Rev  Embarked_C  Embarked_Q  \\\n",
       "0      True      False     False      False       False        True   \n",
       "1     False       True     False      False       False       False   \n",
       "2      True      False     False      False       False        True   \n",
       "3      True      False     False      False       False       False   \n",
       "4     False       True     False      False       False       False   \n",
       "\n",
       "   Embarked_S  \n",
       "0       False  \n",
       "1        True  \n",
       "2       False  \n",
       "3        True  \n",
       "4        True  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Determine Title from Name\n",
    "train_data['Title'] = train_data['Name'].apply(lambda x: x.split('.')[0].split(' ')[-1].strip())\n",
    "test_data['Title'] = test_data['Name'].apply(lambda x: x.split('.')[0].split(' ')[-1].strip())\n",
    "\n",
    "# Drop unnecessary columns\n",
    "train_data.drop(columns=['PassengerId','Name','Ticket'], inplace=True)\n",
    "test_data.drop(columns=['PassengerId','Name','Ticket'], inplace=True)\n",
    "\n",
    "# Transform Cabin into binary 'HasCabin'\n",
    "train_data['Cabin'] = train_data['Cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test_data['Cabin'] = test_data['Cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# One-hot encode 'Pclass', 'Sex', 'SibSp', 'Parch', 'Title' and 'Embarked'\n",
    "train_data = pd.get_dummies(train_data, columns=['Pclass', 'Sex', 'SibSp', 'Parch', 'Title','Embarked'])\n",
    "test_data = pd.get_dummies(test_data, columns=['Pclass', 'Sex', 'SibSp', 'Parch', 'Title','Embarked'])\n",
    "\n",
    "train_data['Age'] = train_data['Age'].fillna(train_data['Age'].median())\n",
    "test_data['Age'] = test_data['Age'].fillna(test_data['Age'].median())\n",
    "\n",
    "# Z-Score normalisation of 'Age' and 'Fare'\n",
    "for column_to_normalise in ['Age', 'Fare']:\n",
    "    mean_value = train_data[column_to_normalise].mean()\n",
    "    std_value = train_data[column_to_normalise].std()\n",
    "    train_data[column_to_normalise] = (train_data[column_to_normalise] - mean_value) / std_value\n",
    "    test_data[column_to_normalise] = (test_data[column_to_normalise] - mean_value) / std_value\n",
    "    \n",
    "train_data.head()\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = set(train_data.columns)\n",
    "test_columns = set(test_data.columns)\n",
    "\n",
    "# Ensure both datasets have the same columns\n",
    "all_columns = train_columns.union(test_columns)\n",
    "\n",
    "# Add missing columns to train_data and set their values to False\n",
    "for column in all_columns:\n",
    "    if column not in train_columns:\n",
    "        train_data[column] = False\n",
    "\n",
    "# Add missing columns to test_data and set their values to False\n",
    "for column in all_columns:\n",
    "    if column not in test_columns:\n",
    "        test_data[column] = False\n",
    "\n",
    "\n",
    "train_data = train_data[sorted(train_data.columns)]\n",
    "test_data = test_data[sorted(test_data.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense MLP Model with L2 regularization and Dropout\n",
      "Sequential(\n",
      "  (hidden1): Linear(in_features=44, out_features=256, bias=True)\n",
      "  (activation1): ReLU()\n",
      "  (dropout1): Dropout(p=0.2, inplace=False)\n",
      "  (hidden2): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (activation2): ReLU()\n",
      "  (dropout2): Dropout(p=0.2, inplace=False)\n",
      "  (hidden3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (activation3): ReLU()\n",
      "  (dropout3): Dropout(p=0.2, inplace=False)\n",
      "  (hidden4): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (activation4): ReLU()\n",
      "  (dropout4): Dropout(p=0.2, inplace=False)\n",
      "  (output): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (activation5): Sigmoid()\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "Simple MLP Model with L2 regularization and Dropout\n",
      "Sequential(\n",
      "  (hidden1): Linear(in_features=44, out_features=8, bias=True)\n",
      "  (activation1): ReLU()\n",
      "  (dropout1): Dropout(p=0.2, inplace=False)\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (activation4): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "dropout_prob = 0.2\n",
    "weight_decay = 1e-5\n",
    "\n",
    "\n",
    "input_size = 44\n",
    "hidden_layer_sizes = [256, 512, 512, 256]\n",
    "\n",
    "\n",
    "model_dense = nn.Sequential(collections.OrderedDict([\n",
    "    ('hidden1', nn.Linear(input_size, hidden_layer_sizes[0])),\n",
    "    ('activation1', nn.ReLU()),\n",
    "    ('dropout1', nn.Dropout(dropout_prob)),  \n",
    "    ('hidden2', nn.Linear(hidden_layer_sizes[0], hidden_layer_sizes[1])),\n",
    "    ('activation2', nn.ReLU()),\n",
    "    ('dropout2', nn.Dropout(dropout_prob)),\n",
    "    ('hidden3', nn.Linear(hidden_layer_sizes[1], hidden_layer_sizes[2])),\n",
    "    ('activation3', nn.ReLU()),\n",
    "    ('dropout3', nn.Dropout(dropout_prob)),\n",
    "    ('hidden4', nn.Linear(hidden_layer_sizes[2], hidden_layer_sizes[3])),\n",
    "    ('activation4', nn.ReLU()),\n",
    "    ('dropout4', nn.Dropout(dropout_prob)),\n",
    "    ('output', nn.Linear(hidden_layer_sizes[3], 1)),\n",
    "    ('activation5', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "\n",
    "simple_hl_sizes = [8]\n",
    "model_simple = nn.Sequential(collections.OrderedDict([\n",
    "    ('hidden1', nn.Linear(input_size, simple_hl_sizes[0])),\n",
    "    ('activation1', nn.ReLU()),\n",
    "    ('dropout1', nn.Dropout(dropout_prob)),\n",
    "    ('output', nn.Linear(simple_hl_sizes[0], 1)),\n",
    "    ('activation4', nn.Sigmoid())\n",
    "        ]))\n",
    "\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer_dense = torch.optim.Adam(model_dense.parameters(), weight_decay=weight_decay)\n",
    "optimizer_simple = torch.optim.Adam(model_simple.parameters(), weight_decay=weight_decay)\n",
    "model_dense.load_state_dict(torch.load('titanic_overfit.pth'))\n",
    "\n",
    "print(\"Dense MLP Model with L2 regularization and Dropout\")\n",
    "print(model_dense)\n",
    "print(\"\\n\\n\")\n",
    "print(\"Simple MLP Model with L2 regularization and Dropout\")\n",
    "print(model_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor torch.FloatTensor torch.FloatTensor\n",
      "torch.Size([891, 44]) torch.Size([891, 1]) torch.Size([418, 44])\n"
     ]
    }
   ],
   "source": [
    "y_train = torch.tensor(train_data[\"Survived\"].values.astype('float32')).reshape(-1,1)\n",
    "X_train = torch.tensor(train_data.drop(columns=[\"Survived\"]).values.astype('float32'))\n",
    "X_test = torch.tensor(test_data.drop(columns=[\"Survived\"]).values.astype('float32'))\n",
    "\n",
    "print(y_train.type(), X_train.type(), X_test.type())\n",
    "print(X_train.shape, y_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "\n",
    "def cross_validate(model, n_epochs, optimizer, loss_fn, X_train, y_train, n_splits=9, batch_size=32, shuffle=True, device=device,epoch_print_gap = 1):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=42)\n",
    "    fold_results = []\n",
    "    train_results = []\n",
    "\n",
    "    for fold, (train_index, valid_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        print(f\"Fold {fold+1}/{n_splits}\")\n",
    "        X_train_fold, X_valid_fold = X_train[train_index], X_train[valid_index]\n",
    "        y_train_fold, y_valid_fold = y_train[train_index], y_train[valid_index]\n",
    "        \n",
    "        train_dataset = torch.utils.data.TensorDataset(X_train_fold, y_train_fold)\n",
    "        valid_dataset = torch.utils.data.TensorDataset(X_valid_fold, y_valid_fold)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "        valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size)\n",
    "\n",
    "        model = model.to(device)\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            model.train()\n",
    "            loss_train = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for X_train_batch, y_train_batch in train_loader:\n",
    "                X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_train_batch)\n",
    "                loss = loss_fn(outputs, y_train_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_train += loss.item()\n",
    "                total += y_train_batch.size(0)\n",
    "                correct += ((outputs > 0.5).float() == y_train_batch).sum().item()\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            accuracy_train = 100 *correct / total\n",
    "\n",
    "            if epoch == 1 or epoch % epoch_print_gap == 0:\n",
    "                print('{} Epoch {}, Training loss {}, Training Accuracy {:.2f}%'.format(\n",
    "                    datetime.datetime.now(), epoch, float(loss_train), float(accuracy_train)))\n",
    "        train_results.append(accuracy_train)\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_valid_batch, y_valid_batch in valid_loader:\n",
    "                X_valid_batch, y_valid_batch = X_valid_batch.to(device), y_valid_batch.to(device)\n",
    "                outputs = model(X_valid_batch)\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                total += y_valid_batch.size(0)\n",
    "                correct += (predicted == y_valid_batch).sum().item()\n",
    "   \n",
    "                \n",
    "\n",
    "                \n",
    "        fold_accuracy = 100 *correct / total\n",
    "        print('Fold Accuracy: {:.2f}%'.format(fold_accuracy))\n",
    "        fold_results.append(fold_accuracy)\n",
    "\n",
    "    return (train_results, fold_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "2024-02-11 20:43:15.933713 Epoch 1, Training loss 307.2314693927765, Training Accuracy 78.37%\n",
      "2024-02-11 20:43:16.423521 Epoch 10, Training loss 175.4782387847954, Training Accuracy 79.49%\n",
      "2024-02-11 20:43:16.968741 Epoch 20, Training loss 94.28002350777388, Training Accuracy 82.02%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-11 20:43:17.512022 Epoch 30, Training loss 72.16690720617771, Training Accuracy 83.43%\n",
      "2024-02-11 20:43:18.050607 Epoch 40, Training loss 97.71007114648819, Training Accuracy 80.90%\n",
      "2024-02-11 20:43:18.589063 Epoch 50, Training loss 49.219271406531334, Training Accuracy 82.72%\n",
      "Fold Accuracy: 84.92%\n",
      "Fold 2/5\n",
      "2024-02-11 20:43:18.647921 Epoch 1, Training loss 50.22479738295078, Training Accuracy 83.87%\n",
      "2024-02-11 20:43:19.138862 Epoch 10, Training loss 37.6967071890831, Training Accuracy 84.71%\n",
      "2024-02-11 20:43:19.682771 Epoch 20, Training loss 49.15202981233597, Training Accuracy 83.45%\n",
      "2024-02-11 20:43:20.226477 Epoch 30, Training loss 22.66711051762104, Training Accuracy 86.96%\n",
      "2024-02-11 20:43:20.767660 Epoch 40, Training loss 10.994400031864643, Training Accuracy 87.10%\n",
      "2024-02-11 20:43:21.308877 Epoch 50, Training loss 10.24284379184246, Training Accuracy 87.80%\n",
      "Fold Accuracy: 86.52%\n",
      "Fold 3/5\n",
      "2024-02-11 20:43:21.367559 Epoch 1, Training loss 25.726189002394676, Training Accuracy 87.80%\n",
      "2024-02-11 20:43:21.844940 Epoch 10, Training loss 10.472617760300636, Training Accuracy 88.08%\n",
      "2024-02-11 20:43:22.370043 Epoch 20, Training loss 10.45500123500824, Training Accuracy 86.54%\n",
      "2024-02-11 20:43:22.904685 Epoch 30, Training loss 6.82108011841774, Training Accuracy 87.94%\n",
      "2024-02-11 20:43:23.444186 Epoch 40, Training loss 6.950542442500591, Training Accuracy 88.92%\n",
      "2024-02-11 20:43:23.982636 Epoch 50, Training loss 6.647489592432976, Training Accuracy 89.34%\n",
      "Fold Accuracy: 82.58%\n",
      "Fold 4/5\n",
      "2024-02-11 20:43:24.041933 Epoch 1, Training loss 8.613044053316116, Training Accuracy 87.38%\n",
      "2024-02-11 20:43:24.528386 Epoch 10, Training loss 7.010017804801464, Training Accuracy 87.24%\n",
      "2024-02-11 20:43:25.070432 Epoch 20, Training loss 7.030040830373764, Training Accuracy 86.96%\n",
      "2024-02-11 20:43:25.602283 Epoch 30, Training loss 6.865110456943512, Training Accuracy 88.22%\n",
      "2024-02-11 20:43:26.133230 Epoch 40, Training loss 9.179740689694881, Training Accuracy 89.76%\n",
      "2024-02-11 20:43:26.661727 Epoch 50, Training loss 6.59746191650629, Training Accuracy 90.04%\n",
      "Fold Accuracy: 86.52%\n",
      "Fold 5/5\n",
      "2024-02-11 20:43:26.719252 Epoch 1, Training loss 7.169864468276501, Training Accuracy 86.82%\n",
      "2024-02-11 20:43:27.177212 Epoch 10, Training loss 6.489661246538162, Training Accuracy 90.46%\n",
      "2024-02-11 20:43:27.674005 Epoch 20, Training loss 5.626013338565826, Training Accuracy 90.18%\n",
      "2024-02-11 20:43:28.170630 Epoch 30, Training loss 6.182395756244659, Training Accuracy 90.60%\n",
      "2024-02-11 20:43:28.669918 Epoch 40, Training loss 6.281694911420345, Training Accuracy 90.88%\n",
      "2024-02-11 20:43:29.166862 Epoch 50, Training loss 5.429604612290859, Training Accuracy 91.30%\n",
      "Fold Accuracy: 82.58%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "train, test = cross_validate(model = model_dense,\n",
    "               n_epochs = n_epochs,\n",
    "               optimizer = optimizer_dense,\n",
    "               loss_fn = loss_fn,\n",
    "               X_train = X_train,\n",
    "               y_train = y_train,\n",
    "               n_splits=5, \n",
    "               batch_size=32, \n",
    "               shuffle=True, \n",
    "               device=device,\n",
    "               epoch_print_gap=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 100.0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(train, label=\"Training Accuracy\")\n",
    "plt.plot(test, label=\"Validation Accuracy\")\n",
    "plt.ylim(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43552/2682251744.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output.loc[:, 'Survived'] = predictions.cpu().numpy().astype(int)\n"
     ]
    }
   ],
   "source": [
    "model_dense = model_dense.to(device)\n",
    "X_test = X_test.to(device)\n",
    "\n",
    "model_dense.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model_dense(X_test)\n",
    "    predictions = (y_pred > 0.5).float()\n",
    "\n",
    "\n",
    "test_ = pd.read_csv('test.csv')\n",
    "output = test_[['PassengerId']]\n",
    "output.loc[:, 'Survived'] = predictions.cpu().numpy().astype(int)\n",
    "\n",
    "output.to_csv('titanic_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model_dense.state_dict(), 'titanic_with_dropout_l2.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
